% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/get-reddit-content.R
\name{get_reddit_content}
\alias{get_reddit_content}
\title{Scrape Content from Multiple URLs and combine into a single data frame}
\usage{
get_reddit_content(content_type = "comment", result_limit = 500,
  timeout = 10, ...)
}
\arguments{
\item{content_type}{A string containing the type of content you want to
query. The pushshift api supports the following options: "comment" and
"submission". This function defaults to "comment" and gets
passed to \code{construct_pushshift_url}.}

\item{result_limit}{An integer representing the maximum number of results to
return. Defaults to 500, which is the maximum number of results that can be
returned in a single pushshift api query URL. Please keep in mind your
available system resources and any potential burden on other servers when
determining the number of rows you need.}

\item{timeout}{An integer representing the maximum amount of time to allow
for retrieving content from a single URL. Defaults to 10 seconds. When
\code{result_limit} is over 500, the timeout resets for every 500 results
that have been returned successfully.}

\item{...}{Additional arguments to pass to \code{construct_pushshift_url} that
are used to build the api query.}
}
\value{
A data.frame with content imported from your query
}
\description{
This is the flagship function of redditr. It is designed to
handle the process of constructing a query, generating URLs that
point to content, and importing that content into R. If lower-level
control over that workflow is needed, please see
\link{construct_pushshift_url} and \link{import_reddit_content_from_url}.
}
\examples{
# get 500 most recent reddit comments avilable from api
recent_comments <- get_reddit_content()

# get 500 most recent posts
recent_posts <- get_reddit_content(content_type = "submission")

# get more than 500 comments
many_recent_comments <- get_reddit_content(
 content_type = "comment",
 result_limit = 1000
)

# wait longer than default 10 seconds per query
patient_query <- get_reddit_content(
content_type = "comment",
timeout = 20
)
# get posts from a specific subreddit
rstats_posts <- get_reddit_content(
  content_type = "submission",
  subreddit = "rstats"
)

# get comments from a specific user
hadley_comments <- get_reddit_content(
  content_type = "comment",
  author = "hadley"
)

# get comments relating to data science
comments_before_christmas <- get_reddit_content(
  content_type = "comment",
  q = "data science"
)

# get comments before a specific date
comments_before_christmas <- get_reddit_content(
  content_type = "comment",
  before = date_to_api("2018-12-25 00:00:00", tz = "EST")
)

# get comments after a specific date
comments_after_christmas <- get_reddit_content(
  content_type = "comment",
  after = date_to_api("2018-12-25 23:59:59", tz = "EST")
)

}
